{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "\n",
    "def normalize_data(train_data, test_data, type=None):\n",
    "    if type is None:\n",
    "        return train_data, test_data\n",
    "    elif type == \"standard\":\n",
    "        scaler = sklearn.preprocessing.StandardScaler()\n",
    "    elif type == \"min_max\":\n",
    "        scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    elif type == \"l1\" or type == \"l2\":\n",
    "        scaler = sklearn.preprocessing.Normalizer(type)\n",
    "    \n",
    "    if scaler is not None:\n",
    "        scaler.fit(train_data)\n",
    "        return scaler.transform(train_data), scaler.transform(test_data)\n",
    "    else:\n",
    "        return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = np.load(\"data/training_sentences.npy\", allow_pickle = True)\n",
    "train_labels = np.load(\"data/training_labels.npy\", allow_pickle = True)\n",
    "test_sentences = np.load(\"data/test_sentences.npy\", allow_pickle = True)\n",
    "test_labels = np.load(\"data/test_labels.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Probably', 'not', 'still', 'going', 'over', 'some', 'stuff', 'here']),\n",
       "       list(['I', 'HAVE', 'A', 'DATE', 'ON', 'SUNDAY', 'WITH', 'WILL']),\n",
       "       list(['Thanks', '4', 'your', 'continued', 'support', 'Your', 'question', 'this', 'week', 'will', 'enter', 'u', 'in2', 'our', 'draw', '4', 'Â£100', 'cash', 'Name', 'the', 'NEW', 'US', 'President', 'txt', 'ans', 'to', '80082']),\n",
       "       list(['Dear', '0776xxxxxxx', 'Uve', 'been', 'invited', 'to', 'XCHAT', 'This', 'is', 'our', 'final', 'attempt', 'to', 'contact', 'u', 'Txt', 'CHAT', 'to', '86688', '150pMsgrcvdHGSuite3422LandsRowW1J6HL', 'LDN', '18yrs']),\n",
       "       list(['I', 'sent', 'my', 'scores', 'to', 'sophas', 'and', 'i', 'had', 'to', 'do', 'secondary', 'application', 'for', 'a', 'few', 'schools', 'I', 'think', 'if', 'you', 'are', 'thinking', 'of', 'applying', 'do', 'a', 'research', 'on', 'cost', 'also', 'Contact', 'joke', 'ogunrinde', 'her', 'school', 'is', 'one', 'me', 'the', 'less', 'expensive', 'ones']),\n",
       "       list(['Kothi', 'print', 'out', 'marandratha']),\n",
       "       list(['Arun', 'can', 'u', 'transfr', 'me', 'd', 'amt']),\n",
       "       list(['I', 'asked', 'you', 'to', 'call', 'him', 'now', 'ok']),\n",
       "       list(['Ringtone', 'Club', 'Gr8', 'new', 'polys', 'direct', 'to', 'your', 'mobile', 'every', 'week']),\n",
       "       list(['Hello', 'Just', 'got', 'here', 'st', 'andrewsboy', 'its', 'a', 'long', 'way', 'Its', 'cold', 'I', 'will', 'keep', 'you', 'posted'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWords:\n",
    "    \n",
    "    '''\n",
    "    Initializare dictionar gol\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vocab = {}\n",
    "        self.words = []\n",
    "        \n",
    "    '''\n",
    "    Construiti dicionarul si data\n",
    "    \n",
    "    data - lista de liste de cuvinte\n",
    "    '''\n",
    "    \n",
    "    def build_dictionary(self, data):\n",
    "        for sentence in data:\n",
    "            for word in sentence:\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab[word] = len(self.words)\n",
    "                    self.words.append(word)\n",
    "        print(len(self.words))\n",
    "        \n",
    "    #N propozitii -> Nx9522\n",
    "    #pt fiecare prop am omatrice de zero-uri\n",
    "    def get_features(self, data):\n",
    "        features = np.zeros((data.shape[0], len(self.words)))\n",
    "        for idx, sentence in enumerate(data):\n",
    "            for word in sentence:\n",
    "                if word in self.vocab:\n",
    "                    features[idx, self.vocab[word]] += 1 #am marcat cuvintele care exista\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9522\n",
      "(3734, 9522)\n",
      "(1840, 9522)\n"
     ]
    }
   ],
   "source": [
    "bow = BagOfWords()\n",
    "bow.build_dictionary(train_sentences)\n",
    "\n",
    "train_features = bow.get_features(train_sentences)\n",
    "test_features = bow.get_features(test_sentences)\n",
    "\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_normalized, test_features_normalized = normalize_data(train_features, test_features, 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35355339, 0.35355339, 0.35355339, 0.35355339, 0.35355339,\n",
       "       0.35355339, 0.35355339, 0.35355339, 0.        , 0.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_normalized[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_normalized, test_features_normalized = normalize_data(train_features, test_features, 'l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.   ,\n",
       "       0.   ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_normalized[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_normalized, test_features_normalized = normalize_data(train_features, test_features, 'min_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.33333333, 1.        , 0.5       , 0.5       ,\n",
       "       0.5       , 0.5       , 0.5       , 0.        , 0.        ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_normalized[0, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC(C=1.0, kernel='linear')\n",
    "\n",
    "model.fit(train_features_normalized, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9815217391304348"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = model.predict(test_features_normalized)\n",
    "\n",
    "accuracy_score(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1585\n",
      "           1       1.00      0.87      0.93       255\n",
      "\n",
      "    accuracy                           0.98      1840\n",
      "   macro avg       0.99      0.93      0.96      1840\n",
      "weighted avg       0.98      0.98      0.98      1840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9522)\n"
     ]
    }
   ],
   "source": [
    "print(model.coef_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05515992 -0.02012771 -0.14455944 ... -0.01373508 -0.01373508\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "weights = np.squeeze(model.coef_)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative ['me' 'taken' 'I' 'work' 'him' 'favour' 'Im' 'Lmaonice' 'Oh' 'infront']\n",
      "Positive ['FREE>RingtoneReply' '85233' 'won' '1' '08718738034' 'mobile' 'REAL'\n",
      " '02070836089' '84484' 'ringtoneking']\n"
     ]
    }
   ],
   "source": [
    "idxes = np.argsort(weights)\n",
    "# print(idxes)\n",
    "words = np.array(bow.words)\n",
    "\n",
    "print('Negative', words[idxes[:10]])\n",
    "print('Positive', words[idxes[-10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
